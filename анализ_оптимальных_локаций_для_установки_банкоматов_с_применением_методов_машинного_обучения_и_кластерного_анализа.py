# -*- coding: utf-8 -*-
"""Анализ оптимальных локаций для установки банкоматов с применением методов машинного обучения и кластерного анализа.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11sGqEjfN9I8QYPSjHQVyYIj5uXnn93Dl

# **Анализ оптимальных локаций для установки банкоматов с применением методов машинного обучения и кластерного анализа.**

Требования к структуре и оформлению итоговой аттестационной работы:

1.	Термины, определения, сокращения
	2. Введение должно включать:
- четкое и краткое обоснование темы исследования;
- актуальность (которая обусловила выбор темы исследования);
- цели и задачи (которые необходимо решить для достижения поставленной цели);
- объект исследования (процесс или явление, порождающее проблемную ситуацию и избранное для изучения);
- предмет исследования (находится в границах объекта – именно на нем должна быть направлена внимание);
- проблема исследования;
- гипотеза исследования;
- методы исследования (использованные для достижения поставленной в проекте цели);
- научная новизна (практическое значение полученных результатов).
	3. Основная часть работы состоит из разделов (подразделов, подпунктов и т.п.) - содержит обзор и анализ литературы по разрабатываемой проблеме, история вопроса, уровень разработанности проблемы в теории и практике, анализ и сопоставление различных точек зрения, и предложение своего мнения и решения проблемы.
	4. Заключение - содержит итоги работы, важнейшие выводы, которые получены студентом в результате работы; рекомендации относительно возможностей практического применения материалов работы.
	5. Приложение. В этот раздел входят нормативно - правовые документы, таблицы, графики, иллюстрации, схемы и т. п.
	6. Список используемых источников. Список используемых источников составляет не менее 10 наименований, выполняется в алфавитном порядке, оформляется строго в соответствии с правилами библиографии.
	7. Правила оформления проектов
	а) Объем работы должен составлять 15-20 страниц печатного текста (без учета приложений), формат А4.
	б) Текст работы следует печатать, соблюдая следующие требования:
	- поля: левое - 30 мм, правое -15 мм, верхнее и нижнее – 20 мм;
	- шрифт размером 14 Times New Roman;
	- межстрочный интервал – полуторный;
	- отступ красной строки – 12,5 мм;
	- выравнивание основного текста по ширине.
	Проектная работа (проект) должна быть оформлена на одной стороне листа бумаги белого цвета формата А 4 (210 х 297 мм).
	Нумерация страниц арабскими цифрами внизу страницы посередине. Титульный лист и содержание не нумеруются, но принимаются за первую и вторую страницу.
	Список используемых источников (не менее 10) выполняется в алфавитном порядке. Оформление строго с правилами библиографии.
	При составлении списка используемых источников, необходимо обратить внимание на следующие требования:
	а) литература используется наиболее современная (не старше 3-4 лет от проведения исследования);
	б) источники последние 10-20 лет — не более 30% от общего числа в списке литературы;
	в) учебники достаточно использовать в количестве 1-3, они представляют наименьшую ценность.

ЗАДАНИЕ
НА ВЫПОЛНЕНИЕ ИТОГОВОЙ АТТЕСТАЦИОННОЙ РАБОТЫ

1. Тема итоговой аттестационной работы: Анализ оптимальных локаций для установки банкоматов с применением методов машинного обучения и кластерного анализа
2. Исходные данные к итоговой аттестационной работе:
•	Пространственные данные из OpenStreetMap о существующих банкоматах, банковских отделениях и городской инфраструктуре
•	Библиотеки для геопространственного анализа (osmnx, geopandas, h3, leafmap)
•	Библиотеки машинного обучения (scikit-learn) для построения прогнозных моделей и кластерного анализа
3. Основные части итоговой аттестационной работы (перечень подлежащих разработке вопросов):
3.1. Сбор и подготовка геопространственных данных:
•	Определение границ исследуемой территории города/района (ROI)
•	Загрузка из OpenStreetMap данных о существующих банкоматах (теги: amenity=atm, amenity=bank и другие)
•	Извлечение данных о торговых объектах (shop=mall, shop=supermarket, shop=department_store и другие)
•	Сбор информации о бизнес-центрах (office=company, office=government и другие), транспортных узлах (railway=station, amenity=bus_station и другие)
•	Загрузка данных о жилой застройке, парковках, остановках общественного транспорта
•	Проецирование всех данных в единую метрическую систему координат для корректного расчета расстояний
3.2. Создание территориальных единиц анализа и инженерия признаков:
•	Построение гексагональной сетки H3 с оптимальным разрешением (8-9 уровень)
•	Расчет плотности финансовой активности: количество магазинов, ресторанов, сервисов в радиусах 200м, 400м (ВСЕ РАДИУСЫ ВЫБИРАЕТЕ САМИ)
•	Подсчет офисных зданий и оценка числа сотрудников в радиусах 300м, 500м
•	Анализ транспортной доступности: остановки, станции метро, вокзалы в радиусе 300м
•	Оценка конкурентной среды: количество существующих банкоматов в радиусах 250м, 500м, 1000м
•	Расчет пешеходной проходимости на основе близости к ключевым объектам
•	Оценка доступности парковочных мест в радиусе 100м
•	Нормализация и масштабирование всех признаков
3.3. Кластерный анализ территорий:
•	Определение оптимального числа кластеров методом локтя и Silhouette Score (диапазон 4-8 кластеров)
•	Применение K-means для выявления типов территорий по финансовой активности
•	Применение DBSCAN для обнаружения аномальных зон с высокой концентрацией банкоматов
•	Характеристика кластеров: "финансовые центры", "торговые зоны", "транспортные хабы", "спальные районы" (КЛАСТЕРЫ ИНТЕРПРЕТИРУЕТЕ САМОСТОЯЛЬНО, ПО СРЕДНИМ ЗНАЧЕНИЯМ ПРИЗНАКОВ В КАЖДОМ И НИХ)
•	Сравнение результатов различных алгоритмов кластеризации
3.4. Применение методов машинного обучения:
•	Формирование целевой переменной на основе расположения успешных существующих банкоматов
•	Обучение ансамблевых моделей классификации: Random Forest (10/50/100 и тд (подбираете сами) деревьев), Gradient Boosting
•	Настройка гиперпараметров через GridSearchCV для максимизации ROC AUC
•	Кросс-валидация (5-fold) и оценка качества по метрикам ROC AUC, F1-score, precision/recall
•	Анализ важности признаков для выявления ключевых факторов успешности локации
3.5. Расчет интегрального показателя потенциала:
•	Оценка привлекательности каждой локации на основе вероятностных предсказаний модели
•	Учет фактора конкуренции через взвешенный индекс насыщенности банкоматами
•	Дополнительный вес для близости к торговым центрам и транспортным узлам (коэффициент 1.3)
•	Формула расчета: ФОРМУЛИРУЕТЕ САМОСТОЯТЕЛЬНО (ПРИМЕР: Потенциал = 0.6 × Привлекательность + 0.4 × (1 - Конкуренция) МОЖНО ДОБАВЛЯТЬ ДОП. КОЭФФИЦИЕНТЫ)
•	Категоризация территорий по уровню потенциала (высокий/средний/низкий)
3.6. Визуализация результатов и формирование рекомендаций:
•	Создание интерактивных карт с тепловым слоем потенциала территорий
•	Выделение топ-20 локаций без прямых конкурентов в радиусе 250м
•	Маркировка существующих банкоматов, банковских отделений и рекомендуемых точек установки
•	Сегментация рекомендаций по типам локаций (ТЦ, транспортные узлы, офисные центры)
•	Расчет потенциального охвата населения и проходимости для каждой рекомендуемой локации
•	Статистический анализ характеристик наиболее перспективных территорий
•	Экспорт координат рекомендуемых локаций с их характеристиками в табличном формате
•	Подготовка аналитического отчета с обоснованием выбора локаций и оценкой ROI

0. Установка и импорт библиотек
Этот блок идет в самом начале.
"""

!pip install geopandas osmnx h3 scikit-learn leafmap pandas numpy matplotlib seaborn kneed folium mapclassify

import geopandas as gpd
import pandas as pd
import numpy as np
import h3
from shapely.geometry import box, Polygon, Point
import osmnx as ox
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, cross_val_score
import leafmap.leafmap as leafmap
import matplotlib.pyplot as plt
import seaborn as sns
from kneed import KneeLocator
import warnings

# Настройки
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)
sns.set_theme(style="whitegrid")

# КОНСТАНТА: Целевая проекция для Москвы (UTM zone 37N)
TARGET_CRS = "EPSG:32637"

"""### 3.1. Сбор и подготовка геопространственных данных
Задача: Загрузить границы ЦАО и объекты инфраструктуры
"""

# --- 1. Определение границ (ROI) ---
place_name = "Central Administrative Okrug, Moscow, Russia"

print(f"1. Скачивание границ: {place_name}...")
try:
    # Скачиваем границы (по умолчанию приходят в WGS84 - EPSG:4326)
    area = ox.geocode_to_gdf(place_name)
    # Проецируем в целевую метрическую систему
    area_proj = area.to_crs(TARGET_CRS)
    print(f"Границы загружены. Площадь: {area_proj.area.iloc[0] / 1e6:.2f} км²")
except Exception as e:
    print(f"Критическая ошибка загрузки границ: {e}")

# --- 2. Загрузка инфраструктуры ---
# Теги OSM
tags = {
    'atms': {'amenity': ['atm', 'bank']},
    'retail': {'shop': ['mall', 'supermarket', 'department_store', 'convenience', 'clothes', 'electronics']},
    'food': {'amenity': ['cafe', 'restaurant', 'fast_food', 'bar', 'pub']},
    'business': {'office': ['company', 'government', 'it', 'lawyer', 'coworking']},
    'transport': {'public_transport': ['stop_position', 'platform'], 'railway': 'subway_entrance', 'highway': 'bus_stop'},
    'residential': {'building': ['apartments', 'residential']}
}

data_layers = {}
roi_polygon = area.geometry[0] # Полигон для обрезки

print("\n2. Загрузка объектов OSM (может занять 1-3 минуты)...")
for layer_name, tag_dict in tags.items():
    try:
        # Скачиваем геометрии
        gdf = ox.features_from_polygon(roi_polygon, tags=tag_dict)

        if not gdf.empty:
            # Оставляем только геометрию для экономии памяти
            gdf = gdf[['geometry']]
            # Проецируем в метры (Москва)
            gdf = gdf.to_crs(TARGET_CRS)
            # Преобразуем полигоны (здания) в центроиды-точки
            gdf['geometry'] = gdf.geometry.centroid

            data_layers[layer_name] = gdf
            print(f"  - {layer_name}: {len(gdf)} объектов")
        else:
            print(f"  - {layer_name}: пусто")

    except Exception as e:
        print(f"  - {layer_name}: ошибка загрузки ({e})")

atms_gdf = data_layers.get('atms')

"""### 3.2. Создание территориальных единиц анализа и инженерия признаков
Задача: Создать гексагональную сетку H3 (Resolution 9), перевести её в EPSG:32637 и посчитать плотность объектов.
"""

# --- 3.2. Создание территориальных единиц (Надежный метод) ---
import h3
from shapely.geometry import Point

print("1. Генерация сетки H3 (метод координатного сканирования)...")
resolution = 9

# Получаем границы в WGS84
area_wgs84 = area.to_crs("EPSG:4326")
roi_poly = area_wgs84.geometry.iloc[0]
minx, miny, maxx, maxy = roi_poly.bounds

# Создаем сетку точек с шагом ~150 метров (0.0015 градуса)
# Это гарантирует, что мы "нащупаем" все гексагоны внутри полигона
lat_steps = np.arange(miny, maxy, 0.0015)
lon_steps = np.arange(minx, maxx, 0.0025)

hex_ids = set()

print(f"Сканирование области ({len(lat_steps)}x{len(lon_steps)} точек)...")
# Проходим по сетке
for lat in lat_steps:
    for lon in lon_steps:
        # Проверяем, попадает ли точка в границы ЦАО
        if roi_poly.contains(Point(lon, lat)):
            # Получаем индекс гексагона
            h_id = h3.latlng_to_cell(lat, lon, resolution)
            hex_ids.add(h_id)

print(f"Успешно создано гексагонов: {len(hex_ids)}")

# 2. Создание геометрии
hex_polys = []
valid_hex_ids = []

for h in hex_ids:
    try:
        boundary = h3.cell_to_boundary(h)
        # H3 (lat, lon) -> Shapely (lon, lat)
        poly_coords = [(coord[1], coord[0]) for coord in boundary]
        hex_polys.append(Polygon(poly_coords))
        valid_hex_ids.append(h)
    except:
        continue

# Создаем DataFrame и проецируем в метры
grid_gdf = gpd.GeoDataFrame({'h3_index': valid_hex_ids}, geometry=hex_polys, crs="EPSG:4326")
grid_proj = grid_gdf.to_crs(TARGET_CRS)

# --- 3. Инженерия признаков (Повтор, так как сетка обновилась) ---
def count_nearby(centroids_gdf, target_gdf, radius_meters):
    if target_gdf is None or target_gdf.empty:
        return pd.Series(0, index=centroids_gdf.index)

    # Буферы
    buffers = centroids_gdf.geometry.buffer(radius_meters)
    buffers_gdf = gpd.GeoDataFrame(geometry=buffers, crs=TARGET_CRS)

    # Spatial Join
    joined = gpd.sjoin(target_gdf, buffers_gdf, how='inner', predicate='intersects')
    return joined.index_right.value_counts().reindex(centroids_gdf.index, fill_value=0)

print("Расчет признаков для новой сетки...")
hex_centroids = grid_proj.copy()
hex_centroids['geometry'] = hex_centroids.geometry.centroid

# Целевая переменная
grid_proj['atm_target'] = 0
if atms_gdf is not None:
    atm_counts = count_nearby(hex_centroids, atms_gdf, 70)
    grid_proj.loc[atm_counts > 0, 'atm_target'] = 1

# Признаки
radii_config = {
    'retail': [300],
    'food': [300],
    'business': [300],
    'transport': [300],
    'residential': [300, 500]
}

for cat, radii in radii_config.items():
    if cat in data_layers:
        for r in radii:
            col_name = f'{cat}_{r}m'
            grid_proj[col_name] = count_nearby(hex_centroids, data_layers[cat], r).values

# Конкуренция
if atms_gdf is not None:
    grid_proj['atm_competitors_300m'] = count_nearby(hex_centroids, atms_gdf, 300).values
else:
    grid_proj['atm_competitors_300m'] = 0

print(f"Готово. Данные: {grid_proj.shape}")
print(grid_proj.head(3))

"""### 3.3. Кластерный анализ территорий
Задача: Сегментировать гексагоны
"""

# --- 3.3. Кластерный анализ территорий ---

# Подготовка данных
feature_cols = [c for c in grid_proj.columns if c not in ['h3_index', 'geometry', 'atm_target']]
X = grid_proj[feature_cols].fillna(0)

# Проверка на наличие данных
if len(X) < 10:
    print(f"ОШИБКА: Слишком мало данных для кластеризации ({len(X)} строк). Проверьте шаг 3.2.")
else:
    # Масштабирование
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # 1. Метод локтя
    wcss = []
    K_range = range(2, 11)

    print("Запуск метода локтя...")
    for i in K_range:
        kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)
        kmeans.fit(X_scaled)
        wcss.append(kmeans.inertia_)

    kl = KneeLocator(K_range, wcss, curve="convex", direction="decreasing")
    optimal_k = kl.elbow if kl.elbow else 4

    print(f"Оптимальное количество кластеров: {optimal_k}")

    # 2. K-Means
    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    grid_proj['cluster'] = kmeans.fit_predict(X_scaled)

    # 3. Визуализация профилей
    cluster_means = grid_proj.groupby('cluster')[feature_cols].mean()
    plt.figure(figsize=(12, 6))
    sns.heatmap(cluster_means.T, cmap="YlGnBu", annot=True, fmt=".1f")
    plt.title("Средние значения признаков по кластерам ЦАО")
    plt.show()

    print("Кластеризация завершена успешно.")

"""### 3.4. Применение методов машинного обучения
Задача: Обучить модель и доказать, что она не переобучилась.
"""

# Разделение данных
y = grid_proj['atm_target']
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42, stratify=y)

# --- Random Forest ---
rf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=4, random_state=42, class_weight='balanced')
rf.fit(X_train, y_train)

# --- Оценка качества ---
y_train_pred = rf.predict(X_train)
y_test_pred = rf.predict(X_test)
y_test_prob = rf.predict_proba(X_test)[:, 1]

print("--- Random Forest Results ---")
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")
print(f"Test Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}")
print(f"Test ROC AUC:   {roc_auc_score(y_test, y_test_prob):.4f}")

# --- ПРОВЕРКА НА ПЕРЕОБУЧЕНИЕ (Learning Curves) ---
def plot_learning_curve(estimator, title, X, y, cv=5):
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 5), scoring='roc_auc'
    )

    train_scores_mean = np.mean(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)

    plt.figure(figsize=(8, 5))
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")
    plt.title(title)
    plt.xlabel("Training examples")
    plt.ylabel("ROC AUC Score")
    plt.legend(loc="best")
    plt.grid()
    plt.show()

    # Анализ разрыва
    gap = np.mean(train_scores_mean - test_scores_mean)
    print(f"Средний разрыв между Train и CV (Gap): {gap:.4f}")
    if gap > 0.1:
        print("⚠️ ВНИМАНИЕ: Возможен Overfitting (переобучение).")
    elif train_scores_mean[-1] < 0.7:
        print("⚠️ ВНИМАНИЕ: Возможен Underfitting (недообучение).")
    else:
        print("✅ Модель сбалансирована.")

plot_learning_curve(rf, "Learning Curve (Random Forest)", X_train, y_train)

# Важность признаков
feat_imp = pd.DataFrame({'Feature': feature_cols, 'Importance': rf.feature_importances_})
feat_imp = feat_imp.sort_values('Importance', ascending=False).head(10)

"""### 3.5. Расчет интегрального показателя потенциала
Задача: Рассчитать скор для каждой локации.
"""

# 1. Предсказание вероятности успеха (Probability)
# Используем predict_proba для всего датасета
grid_proj['prob_success'] = rf.predict_proba(X_scaled)[:, 1]

# 2. Фактор конкуренции (Inverse Competition)
# Чем больше банкоматов рядом, тем меньше этот коэффициент.
# Используем логарифмирование для сглаживания выбросов
grid_proj['competition_factor'] = 1 / (np.log1p(grid_proj['atm_competitors_300m']) + 1)

# 3. Интегральный показатель (Формула)
# Potential = 0.6 * Вероятность + 0.4 * Фактор_Конкуренции
# Мы ищем места, где модель говорит "здесь должен быть банкомат", но конкурентов мало.
grid_proj['potential_score'] = (0.6 * grid_proj['prob_success']) + (0.4 * grid_proj['competition_factor'])

# 4. Фильтр
# Убираем гексагоны, где УЖЕ есть наши банкоматы (atm_target == 1)
candidates = grid_proj[grid_proj['atm_target'] == 0].copy()

# Категоризация
candidates['potential_cat'] = pd.qcut(candidates['potential_score'], q=[0, 0.5, 0.8, 1], labels=['Low', 'Medium', 'High'])

print("Расчет потенциала выполнен.")
print(candidates[['h3_index', 'potential_score', 'potential_cat']].head())

"""### 3.6. Визуализация результатов и формирование рекомендаций
Задача: Карта и отчет.
"""

# 3.6. Визуализация результатов
import matplotlib.cm as cm
import matplotlib.colors as mcolors
from IPython.display import display, HTML

# 1. Подготовка данных
candidates_wgs = candidates.to_crs("EPSG:4326").copy()
atms_wgs = atms_gdf.to_crs("EPSG:4326").copy()
top_20_wgs = top_20.to_crs("EPSG:4326").copy()

top_20_points = top_20_wgs.copy()
top_20_points['geometry'] = top_20_points.geometry.centroid

# 2. Цветовая схема
norm = mcolors.Normalize(vmin=candidates_wgs['potential_score'].min(), vmax=candidates_wgs['potential_score'].max())
cmap = cm.get_cmap('plasma')

def get_hex_color(score):
    rgba = cmap(norm(score))
    return mcolors.to_hex(rgba)

# 3. Настройка карты
# draw_control=False отключает стандартную рисовалку, мы добавим инструменты и переместим их
m = leafmap.Map(center=[55.7539, 37.6208], zoom=13, draw_control=False, measure_control=False)

# --- CSS ХАК для перемещения Toolbar в центр слева ---
# Это переопределяет стили контейнера Leaflet, сдвигая левый верхний угол вниз на 50%
css = """
<style>
.leaflet-top.leaflet-left {
    top: 50% !important;
    transform: translateY(-50%) !important;
    margin-top: 0 !important;
}
</style>
"""
display(HTML(css))

# --- СЛОЙ 1: Тепловая карта (Потенциал) - ВКЛЮЧЕН ---
m.add_gdf(
    candidates_wgs,
    layer_name="1. Тепловая карта (Потенциал)",
    style_callback=lambda x: {
        "fillColor": get_hex_color(x['properties']['potential_score']),
        "color": get_hex_color(x['properties']['potential_score']),
        "weight": 1,
        # Объемный эффект через прозрачность
        "fillOpacity": 0.8 if x['properties']['potential_cat'] == 'High' else 0.2,
    },
    hover_style={"fillOpacity": 1.0, "weight": 2, "color": "white"}
)

# --- СЛОЙ 2: Существующие банкоматы - ОТКЛЮЧЕН ПО УМОЛЧАНИЮ ---
#m.add_gdf(
#    atms_wgs,
#    layer_name="2. Существующие банкоматы",
#    style={"color": "#888888", "radius": 2, "fillOpacity": 0.6}
#)

# --- СЛОЙ 3: Топ-20 Рекомендаций - ВКЛЮЧЕН ---
m.add_gdf(
    top_20_points,
    layer_name="3. Топ-20 Рекомендаций (Синие)",
    style={"color": "#00FFFF", "fillColor": "#00FFFF", "opacity": 1, "fillOpacity": 0.8, "weight": 2, "radius": 6}
)

# Добавляем легенду
m.add_colormap(
    'plasma',
    vmin=candidates_wgs['potential_score'].min(),
    vmax=candidates_wgs['potential_score'].max(),
    label="Potential Score",
    orientation="horizontal"
)

print("Карта готова. Синими метками обозначены  Топ-20 лучших мест для банкоматов")
m

# --- Отчет ---
print("=== АНАЛИТИЧЕСКИЙ ОТЧЕТ (ЦАО, Москва) ===")
print(f"Всего проанализировано зон: {len(grid_proj)}")
print(f"Выбрано Топ-20 локаций со средним потенциалом: {top_20['potential_score'].mean():.3f}")
print("\nКлючевые драйверы (важность признаков):")
print(feat_imp)
print("\nХарактеристика лучшей точки:")
best_loc = top_20.iloc[0]
print(f"Индекс: {best_loc['h3_index']}")
print(f"Торговли рядом (300м): {best_loc['retail_300m']}")
print(f"Офисов рядом (300м): {best_loc['business_300m']}")
print(f"Конкурентов (300м): {best_loc['atm_competitors_300m']}")

# Сохранение
top_20.drop(columns=['geometry']).to_csv("moscow_cao_atm_recommendations.csv")